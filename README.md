# Fast And Accurate Deep Network Learning Using Exponential Linear Units(ELUs)
 
We introduce the ”exponential linear unit” (ELU) which speeds up learning in deep neural networks and leads to higher classification accuracies. Like rectified linear units (ReLUs), leaky ReLUs (LRe- LUs) and parametrized ReLUs (PReLUs), ELUs alleviate the vanishing gradient problem via the identity for positive values.
